{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANNs with MNIST Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "import matplotlib.pyplot as plt #Graph\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential #ANN architecture\n",
    "from tensorflow.keras.layers import Dense #The layers in the ANN\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape (30596, 784)\n",
      "y_class_train.shape (30596, 1)\n",
      "Classes: [0 1 2 3 4]\n",
      "N_classes = 5\n"
     ]
    }
   ],
   "source": [
    "x_train = pd.DataFrame(pd.read_csv(\"mnist_train.csv\"))\n",
    "x_test = pd.DataFrame(pd.read_csv(\"mnist_test.csv\"))\n",
    "\n",
    "x_train = x_train[x_train['label']<5]\n",
    "y_class_train = x_train[['label']]\n",
    "x_train = x_train.drop(columns=['label'])\n",
    "x_train = x_train/255 \n",
    "print(\"x_train.shape\",x_train.shape)\n",
    "print(\"y_class_train.shape\",y_class_train.shape)\n",
    "x_test = x_test[x_test['label']<5]\n",
    "y_class_test = x_test[['label']]\n",
    "x_test = x_test.drop(columns=['label'])\n",
    "x_test = x_test/255\n",
    "\n",
    "classes = np.unique(y_class_train)\n",
    "print(\"Classes:\",classes)\n",
    "N_classes = len(classes)\n",
    "print(\"N_classes =\",N_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_sigmoid = Sequential()\n",
    "ann_sigmoid.add(layers.Dense(N_classes, activation='sigmoid', input_shape=(28 * 28,))) #input layer\n",
    "ann_sigmoid.add(layers.Dense(N_classes, activation='sigmoid')) #hidden layer\n",
    "ann_sigmoid.add(layers.Dense(N_classes, activation='sigmoid'))#output layer\n",
    "ann_sigmoid.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_class_train_onehotencode = to_categorical(y_class_train)\n",
    "y_class_test_onehotencode = to_categorical(y_class_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "957/957 [==============================] - 1s 516us/step - loss: 1.2348 - accuracy: 0.7335\n",
      "Epoch 2/5\n",
      "957/957 [==============================] - 1s 523us/step - loss: 0.6994 - accuracy: 0.9123\n",
      "Epoch 3/5\n",
      "957/957 [==============================] - 0s 509us/step - loss: 0.4379 - accuracy: 0.9323\n",
      "Epoch 4/5\n",
      "957/957 [==============================] - 0s 501us/step - loss: 0.3097 - accuracy: 0.9425\n",
      "Epoch 5/5\n",
      "957/957 [==============================] - 0s 503us/step - loss: 0.2324 - accuracy: 0.9513\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1bdbf02c670>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train\n",
    "ann_sigmoid.fit(x_train, y_class_train_onehotencode, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161/161 [==============================] - 0s 411us/step - loss: 0.1833 - accuracy: 0.9582\n",
      "test_acc: 0.9581630825996399 test_loss 0.1833181083202362\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96       980\n",
      "           1       0.99      0.99      0.99      1135\n",
      "           2       0.94      0.92      0.93      1032\n",
      "           3       0.96      0.93      0.95      1010\n",
      "           4       0.96      0.97      0.96       982\n",
      "\n",
      "    accuracy                           0.96      5139\n",
      "   macro avg       0.96      0.96      0.96      5139\n",
      "weighted avg       0.96      0.96      0.96      5139\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Test set evaluation\n",
    "test_loss_sigmoid, test_acc_sigmoid = ann_sigmoid.evaluate(x_test, y_class_test_onehotencode)\n",
    "print('test_acc:', test_acc_sigmoid, 'test_loss', test_loss_sigmoid)\n",
    "\n",
    "y_pred_test = ann_sigmoid.predict(x_test)\n",
    "y_pred_test = np.argmax(y_pred_test, axis = 1)\n",
    "\n",
    "print(classification_report(y_class_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLu, sigmoid, softmax activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_relu_sigmoid = Sequential()\n",
    "ann_relu_sigmoid.add(layers.Dense(N_classes, activation='sigmoid', input_shape=(28 * 28,))) #input layer\n",
    "ann_relu_sigmoid.add(layers.Dense(N_classes, activation='relu'))#hidden layer\n",
    "ann_relu_sigmoid.add(layers.Dense(N_classes, activation='softmax'))#output layer\n",
    "ann_relu_sigmoid.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "957/957 [==============================] - ETA: 0s - loss: 0.9186 - accuracy: 0.74 - 1s 511us/step - loss: 0.8919 - accuracy: 0.7580\n",
      "Epoch 2/5\n",
      "957/957 [==============================] - 0s 515us/step - loss: 0.3090 - accuracy: 0.9569\n",
      "Epoch 3/5\n",
      "957/957 [==============================] - 0s 513us/step - loss: 0.1364 - accuracy: 0.9667\n",
      "Epoch 4/5\n",
      "957/957 [==============================] - 1s 528us/step - loss: 0.1108 - accuracy: 0.9707\n",
      "Epoch 5/5\n",
      "957/957 [==============================] - 0s 516us/step - loss: 0.1004 - accuracy: 0.9725\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1bdc1d0fb80>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_relu_sigmoid.fit(x_train, y_class_train_onehotencode, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161/161 [==============================] - 0s 455us/step - loss: 0.0846 - accuracy: 0.9774\n",
      "test_acc: 0.9774275422096252 test_loss 0.08458127826452255\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       980\n",
      "           1       0.99      0.99      0.99      1135\n",
      "           2       0.97      0.95      0.96      1032\n",
      "           3       0.97      0.97      0.97      1010\n",
      "           4       0.97      0.98      0.98       982\n",
      "\n",
      "    accuracy                           0.98      5139\n",
      "   macro avg       0.98      0.98      0.98      5139\n",
      "weighted avg       0.98      0.98      0.98      5139\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Test set evaluation\n",
    "test_loss_relu_sigmoid, test_acc_relu_sigmoid = ann_relu_sigmoid.evaluate(x_test, y_class_test_onehotencode)\n",
    "print('test_acc:', test_acc_relu_sigmoid, 'test_loss', test_loss_relu_sigmoid)\n",
    "\n",
    "y_pred_test = ann_relu_sigmoid.predict(x_test)\n",
    "y_pred_test = np.argmax(y_pred_test, axis = 1)\n",
    "\n",
    "print(classification_report(y_class_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLu, softmax activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_relu_softmax = Sequential()\n",
    "ann_relu_softmax.add(layers.Dense(N_classes, activation='relu', input_shape=(28 * 28,))) #input layer\n",
    "ann_relu_softmax.add(layers.Dense(N_classes, activation='relu'))#hidden layer\n",
    "ann_relu_softmax.add(layers.Dense(N_classes, activation='softmax'))#output layer\n",
    "ann_relu_softmax.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "957/957 [==============================] - 1s 518us/step - loss: 0.3795 - accuracy: 0.8786\n",
      "Epoch 2/5\n",
      "957/957 [==============================] - 0s 510us/step - loss: 0.1259 - accuracy: 0.9644\n",
      "Epoch 3/5\n",
      "957/957 [==============================] - 0s 511us/step - loss: 0.1060 - accuracy: 0.9707\n",
      "Epoch 4/5\n",
      "957/957 [==============================] - 0s 511us/step - loss: 0.0957 - accuracy: 0.9730\n",
      "Epoch 5/5\n",
      "957/957 [==============================] - 0s 513us/step - loss: 0.0890 - accuracy: 0.9745\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1bde69dfc70>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_relu_softmax.fit(x_train, y_class_train_onehotencode, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161/161 [==============================] - 0s 443us/step - loss: 0.0800 - accuracy: 0.9786\n",
      "test_acc: 0.9785950779914856 test_loss 0.07996530830860138\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       980\n",
      "           1       0.99      0.99      0.99      1135\n",
      "           2       0.97      0.95      0.96      1032\n",
      "           3       0.98      0.97      0.98      1010\n",
      "           4       0.98      0.98      0.98       982\n",
      "\n",
      "    accuracy                           0.98      5139\n",
      "   macro avg       0.98      0.98      0.98      5139\n",
      "weighted avg       0.98      0.98      0.98      5139\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Test set evaluation\n",
    "test_loss_relu_softmax, test_acc_relu_softmax = ann_relu_softmax.evaluate(x_test, y_class_test_onehotencode)\n",
    "print('test_acc:', test_acc_relu_softmax, 'test_loss', test_loss_relu_softmax)\n",
    "\n",
    "y_pred_test = ann_relu_softmax.predict(x_test)\n",
    "y_pred_test = np.argmax(y_pred_test, axis = 1)\n",
    "\n",
    "print(classification_report(y_class_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
